{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8a5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from matplotlib import rcParams\n",
    "#importing sklearn models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556b4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419d06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining data path\n",
    "data_path=Path('../0.resources/Cleaned_folder/aqi_asthma.csv')\n",
    "\n",
    "#data_path=Path('resources/Cleaned_folder/aqi_asthma_try.csv')\n",
    "\n",
    "# Reading data source using pandas\n",
    "asthma_df=pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2800572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Age_Group', 'county', 'Number_of_Asthma_ED_Visits',\n",
       "       'Age_Adjusted_Rate_of_Asthma_ED_V', 'NO2 AQI_mean', 'NO2 AQI_max',\n",
       "       'NO2 AQI_min', 'O3 AQI_mean', 'O3 AQI_max', 'O3 AQI_min',\n",
       "       'SO2 AQI_mean', 'SO2 AQI_max', 'SO2 AQI_min', 'CO AQI_mean',\n",
       "       'CO AQI_max', 'CO AQI_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asthma_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91057a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "115b92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df_O3.to_html('asthma2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e235cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "asthma_df_O3=asthma_df[['Age_Group', 'county', 'Number_of_Asthma_ED_Visits',\n",
    "       'Age_Adjusted_Rate_of_Asthma_ED_V',  'O3 AQI_mean', 'O3 AQI_max', 'O3 AQI_min',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b1b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                                  int64\n",
       "Age_Group                             int64\n",
       "county                               object\n",
       "Number_of_Asthma_ED_Visits          float64\n",
       "Age_Adjusted_Rate_of_Asthma_ED_V    float64\n",
       "O3 AQI_mean                         float64\n",
       "O3 AQI_max                          float64\n",
       "O3 AQI_min                          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asthma_df_O3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825f2035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature matrix (X)\n",
    "#selecting all columns except 'Age-adjusted-rate'\n",
    "X=asthma_df_O3.drop(['Age_Adjusted_Rate_of_Asthma_ED_V','Number_of_Asthma_ED_Visits','Year','county'], axis=1) \n",
    "\n",
    "#X=asthma_df.drop(['Age-adjusted rate','county'], axis=1)\n",
    "\n",
    "# create response vector (y)\n",
    "##selecting 'Age-adjusted-rate'\n",
    "y=asthma_df_O3['Age_Adjusted_Rate_of_Asthma_ED_V'].values\n",
    "\n",
    "#y=asthma_df['Age-adjusted rate'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d55afc2",
   "metadata": {},
   "source": [
    "#### Splitting data in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa9f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set**: Used to train the classifier.\n",
    "#Testing set**: Used to estimate the error rate of the trained classifier.\n",
    "#Also using train_index and test_index to get train and test data index \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                               X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e06c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train=(83, 4)\n",
      "Shape of X_test=(21, 4)\n",
      "Shape of y_train=(83,)\n",
      "Shape of X_test=(21,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train={X_train.shape}')\n",
    "print(f'Shape of X_test={X_test.shape}')\n",
    "print(f'Shape of y_train={y_train.shape}')\n",
    "print(f'Shape of X_test={y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c19ceb",
   "metadata": {},
   "source": [
    "#### Scaling using standard scaler on feature matrix (X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6fd90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different columns have differnt scale so standrazied it \n",
    "#features scaling using standard scaler on x only\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler=StandardScaler()\n",
    "scaled_X_train=std_scaler.fit_transform(X_train)\n",
    "scaled_X_test=std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328236aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 4)\n",
      "(104,)\n"
     ]
    }
   ],
   "source": [
    "#shape of the X and y\n",
    "print(scaled_X_train.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5471e9",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a54ade",
   "metadata": {},
   "source": [
    "To evaluate a model, we also need an **evaluation metric:**\n",
    "\n",
    "- A numeric calculation used to **quantify** the performance of a model.\n",
    "- The appropriate metric depends on the **goals** of your problem.\n",
    "\n",
    "The most common choices for regression problems are:\n",
    "\n",
    "- **R-squared**: The percentage of variation explained by the model (a \"reward function,\" as higher is better).\n",
    "- **Mean squared error**: The average squared distance between the prediction and the correct answer (a \"loss function,\" as lower is better).\n",
    "- **Mean absolute error**: The average absolute distance between the prediction and the correct answer (a \"loss function,\" as lower is better).\n",
    "\n",
    "In this case, we'll use mean squared error, R2, and mean absolute error because it is more interpretable in a predictive context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35245a8c",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1108050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using linear regression\n",
    "# Make a linear regression instance\n",
    "lr=LinearRegression()\n",
    "# Training the model on the data, storing the information learned from the data\n",
    "# Model is learning the relationship between X and y \n",
    "lr.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c3946d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.41474033905301244\n",
      "R2 Score of testing  set  0.4373255461236534\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {lr.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing  set  {lr.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86461753",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds.\n",
    "-  Cross valiation allows the training set into distinct subsets called folds.\n",
    "- A model is trained using k-1 of the folds as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3794a1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-21.82060501, -21.66038527, -17.33569076, -22.50264052,\n",
       "       -12.98015771])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63129243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Linear Regression is 0.12441727502598798\n",
      "The mean squared error of Linear Regression is 25.016387406162774\n",
      "The mean absolute error of Linear Regression is 19.25989585368098\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lr_r2=np.mean(cross_val_score(lr, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Linear Regression is {lr_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lr_mse=np.mean(cross_val_score(lr, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lr_rmse=np.sqrt(-(lr_mse))\n",
    "print(f'The mean squared error of Linear Regression is {lr_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lr_mae=np.mean(cross_val_score(lr, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lr_mae=(-(lr_mae))\n",
    "print(f'The mean absolute error of Linear Regression is {lr_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a9a3c",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03a85890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using ridge regression(ridge make some features going to near zero)\n",
    "#alpha=0 no regularization( all features are used)\n",
    "# Make a ridge regression instance\n",
    "lr_r=Ridge()\n",
    "lr_r.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8c6ae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.4146384290419671\n",
      "R2 Score of testing set  0.43354352170784693\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {lr_r.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {lr_r.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c192db0",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "030b7d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20.50322637, -20.67679948, -17.5815936 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr_r, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd5d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Ridge Regression is 0.13598442989112783\n",
      "The mean squared error of Ridge Regression is 24.931466001870678\n",
      "The mean absolute error of Ridge Regression is 19.14386047389361\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lr_r_r2=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Ridge Regression is {lr_r_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lr_r_mse=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lr_r_rmse=np.sqrt(-(lr_r_mse))\n",
    "print(f'The mean squared error of Ridge Regression is {lr_r_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lr_r_mae=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lr_r_mae=(-(lr_r_mae))\n",
    "print(f'The mean absolute error of Ridge Regression is {lr_r_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "745ae8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#choosing the best alpha\n",
    "alpha=[]\n",
    "error=[]\n",
    "for i in range(1,1000,50):\n",
    "    alpha.append(i/10)\n",
    "    lrr=Ridge(alpha=(i/10))\n",
    "    error.append(np.mean(cross_val_score(lrr, scaled_X_train, y_train, scoring='neg_mean_absolute_error',\n",
    "                                         cv=5)))\n",
    "plt.plot(alpha,error) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f39c0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing the best alpha (look figure where alpha start to saturate)\n",
    "lrr=Ridge(alpha=10)\n",
    "lrr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc3735f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set with alpha 40 0.24239976912676398\n",
      "R2 Score of testing set with alpha 40 0.3018575249435965\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set \n",
    "print(f'R2 Score of training set with alpha 40 {lrr.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set with alpha 40 {lrr.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa4d5b",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e664a153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20.50322637, -20.67679948, -17.5815936 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr_r, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a89abb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Ridge Regression with alpha 10 is 0.18776344398862516\n",
      "The mean squared error of Ridge Regression with alpha 10 is 24.931466001870678\n",
      "The mean absolute error of Ridge Regression with alpha 10 is 19.14386047389361\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lrr_r2=np.mean(cross_val_score(lrr, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Ridge Regression with alpha 10 is {lrr_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lrr_mse=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lrr_rmse=np.sqrt(-(lrr_mse))\n",
    "print(f'The mean squared error of Ridge Regression with alpha 10 is {lrr_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lrr_mae=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lrr_mae=(-(lrr_mae))\n",
    "print(f'The mean absolute error of Ridge Regression with alpha 10 is {lrr_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea25650",
   "metadata": {},
   "source": [
    "## Laso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d107de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using lassoregression(lasso make some features going to exactly zero)\n",
    "#alpha=0 no regularization( all features are used)\n",
    "# Make a lasso regression instance\n",
    "lr_l=Lasso()\n",
    "lr_l.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcaea044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.41131352130776966\n",
      "R2 Score of testing set  0.4284004894943124\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {lr_l.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {lr_l.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fe47e9",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b420cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.14988726, -18.41962506, -17.39016643])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr_l, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47fbcf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Lasso Regression is 0.34186062297133285\n",
      "The mean squared error of Lasso Regression is 24.638206292946744\n",
      "The mean absolute error of Lasso Regression is 18.85188697019579\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lr_l_r2=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=2))\n",
    "print(f'The R2 of Lasso Regression is {lr_l_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lr_l_mse=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lr_l_rmse=np.sqrt(-(lr_l_mse))\n",
    "print(f'The mean squared error of Lasso Regression is {lr_l_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lr_l_mae=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lr_l_mae=(-(lr_l_mae))\n",
    "print(f'The mean absolute error of Lasso Regression is {lr_l_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07e6a119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#choosing the best alpha\n",
    "alpha=[]\n",
    "error=[]\n",
    "for i in range(1,100,10):\n",
    "    alpha.append(i/10)\n",
    "    lrl=Lasso(alpha=(i/10))\n",
    "    error.append(np.mean(cross_val_score(lrl, scaled_X_train, y_train, scoring='neg_mean_absolute_error',\n",
    "                                         cv=5)))\n",
    "plt.plot(alpha,error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "325b071e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing the best alpha\n",
    "lrl=Lasso(alpha=10)\n",
    "lrl.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "926e06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set with alpha 10 0.30267850496357285\n",
      "R2 Score of testing set with alpha 10 0.28237914152090693\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set \n",
    "print(f'R2 Score of training set with alpha 10 {lrl.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set with alpha 10 {lrl.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529da02",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bd3b904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.14988726, -18.41962506, -17.39016643])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr_l, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3174eb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Lasso Regression with alpha 10 is 0.18568445085525576\n",
      "The mean squared error of Lasso Regression with alpha 10 is 24.638206292946744\n",
      "The mean absolute error of Lasso Regressionwith alpha 10 is 18.85188697019579\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lrl_r2=np.mean(cross_val_score(lrl, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Lasso Regression with alpha 10 is {lrl_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lrl_mse=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lrl_rmse=np.sqrt(-(lrl_mse))\n",
    "print(f'The mean squared error of Lasso Regression with alpha 10 is {lrl_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lrl_mae=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lrl_mae=(-(lrl_mae))\n",
    "print(f'The mean absolute error of Lasso Regressionwith alpha 10 is {lrl_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078bc8d9",
   "metadata": {},
   "source": [
    "## Support Vector Machine(SVM) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac447347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(epsilon=1.5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a svm regression instance\n",
    "svm=LinearSVR(epsilon=1.5)\n",
    "svm.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa4db52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set -0.05992190412405951\n",
      "R2 Score of testing set  0.04357863482048252\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {svm.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {svm.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69553617",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81fb36cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-30.73798964, -23.18171968, -32.0721549 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(svm, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3e0db03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of svm Regression is -0.5325886228015573\n",
      "The mean squared error of svm Regression is 35.63609460841781\n",
      "The mean absolute error of svm Regression is 26.843737493778065\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "svm_r2=np.mean(cross_val_score(svm, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of svm Regression is {svm_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "svm_mse=np.mean(cross_val_score(svm, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "svm_rmse=np.sqrt(-(svm_mse))\n",
    "print(f'The mean squared error of svm Regression is {svm_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "svm_mae=np.mean(cross_val_score(svm, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "svm_mae=(-(svm_mae))\n",
    "print(f'The mean absolute error of svm Regression is {svm_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b70e047",
   "metadata": {},
   "source": [
    "## Support Vector Machine(SVR) Kernel Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f42f0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a svm regression instance\n",
    "svr=SVR(kernel='linear')\n",
    "svr.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9642db51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.37363925541273124\n",
      "R2 Score of testing set  0.3209092134215076\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {svr.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {svr.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9dc1c",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "020c6d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-19.31059148, -19.7592752 , -18.65774348])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(svr, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e2dbda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of svr is 0.18020947869994428\n",
      "The mean squared error of svr is 26.14717990102985\n",
      "The mean absolute error of svr  is 19.75985893737263\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "svr_r2=np.mean(cross_val_score(svr, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of svr is {svr_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "svr_mse=np.mean(cross_val_score(svr, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "svr_rmse=np.sqrt(-(svr_mse))\n",
    "print(f'The mean squared error of svr is {svr_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "svr_mae=np.mean(cross_val_score(svr, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "svr_mae=(-(svr_mae))\n",
    "print(f'The mean absolute error of svr  is {svr_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78110f10",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12eea087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a decision tree instance\n",
    "dt=DecisionTreeRegressor()\n",
    "dt.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b15ed20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 1.0\n",
      "R2 Score of testing set  0.3444824360347106\n"
     ]
    }
   ],
   "source": [
    "#Printing the score of test and train set\n",
    "print(f'R2 Score of training set {dt.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {dt.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5e7b1",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93d73a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.42140687, -26.53805411, -15.88722899])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(dt, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2493a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Decision Tree Regressor is -0.001890304643882068\n",
      "The mean squared error of Decision Tree Regressor is 25.018930799677246\n",
      "The mean absolute error of Decision Tree Regressor is 17.345977569923342\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "dt_r2=np.mean(cross_val_score(dt, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Decision Tree Regressor is {dt_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "dt_mse=np.mean(cross_val_score(dt, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "dt_rmse=np.sqrt(-(dt_mse))\n",
    "print(f'The mean squared error of Decision Tree Regressor is {dt_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "dt_mae=np.mean(cross_val_score(dt, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "dt_mae=(-(dt_mae))\n",
    "print(f'The mean absolute error of Decision Tree Regressor is {dt_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc977383",
   "metadata": {},
   "source": [
    "### Tuning hyperparamaters  using Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a031afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 8, 12],\n",
       "                         'min_samples_leaf': range(1, 5)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "              'max_depth':[6, 8,12],\n",
    "              'min_samples_leaf':range(1,5)}\n",
    "gs_dt=GridSearchCV(dt, param_grid=parameters, \n",
    "                    cv=3, verbose=1, n_jobs=-1)\n",
    "gs_dt.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b44b0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "gs_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4b83bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimator\n",
    "dt_b=gs_dt.best_estimator_\n",
    "dt_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32515322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set after hyperpar tuining 0.8946926164993655\n",
      "R2 Score of testing set after hyperpar tuining  0.4099796597112151\n"
     ]
    }
   ],
   "source": [
    "#Printing the score of test and train set\n",
    "dt_tr=dt_b.score(scaled_X_train, y_train)\n",
    "dt_te=dt_b.score(scaled_X_test, y_test)\n",
    "print(f'R2 Score of training set after hyperpar tuining {dt_tr}')\n",
    "print(f'R2 Score of testing set after hyperpar tuining  {dt_te}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3aed57c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.278476</td>\n",
       "      <td>-0.129841</td>\n",
       "      <td>0.574093</td>\n",
       "      <td>0.240909</td>\n",
       "      <td>0.288605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.289902</td>\n",
       "      <td>-0.784817</td>\n",
       "      <td>0.617732</td>\n",
       "      <td>0.040939</td>\n",
       "      <td>0.599039</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.363173</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>0.430428</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>0.437195</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 4}</td>\n",
       "      <td>0.498626</td>\n",
       "      <td>-0.286714</td>\n",
       "      <td>0.213057</td>\n",
       "      <td>0.141656</td>\n",
       "      <td>0.324565</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.279088</td>\n",
       "      <td>-0.872211</td>\n",
       "      <td>0.508381</td>\n",
       "      <td>-0.028248</td>\n",
       "      <td>0.604070</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.300770</td>\n",
       "      <td>-0.785020</td>\n",
       "      <td>0.597665</td>\n",
       "      <td>0.037805</td>\n",
       "      <td>0.594316</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.442840</td>\n",
       "      <td>-0.468052</td>\n",
       "      <td>0.436243</td>\n",
       "      <td>0.137011</td>\n",
       "      <td>0.427852</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 4}</td>\n",
       "      <td>0.498626</td>\n",
       "      <td>-0.286714</td>\n",
       "      <td>0.213057</td>\n",
       "      <td>0.141656</td>\n",
       "      <td>0.324565</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.293987</td>\n",
       "      <td>-0.533830</td>\n",
       "      <td>0.520650</td>\n",
       "      <td>0.093602</td>\n",
       "      <td>0.453209</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.281352</td>\n",
       "      <td>-0.785720</td>\n",
       "      <td>0.585089</td>\n",
       "      <td>0.026907</td>\n",
       "      <td>0.587841</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.442840</td>\n",
       "      <td>-0.528800</td>\n",
       "      <td>0.436243</td>\n",
       "      <td>0.116761</td>\n",
       "      <td>0.456489</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_leaf': 4}</td>\n",
       "      <td>0.483526</td>\n",
       "      <td>-0.286714</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.178904</td>\n",
       "      <td>0.334422</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001602      0.000174         0.000745        0.000057   \n",
       "1        0.001073      0.000165         0.000650        0.000025   \n",
       "2        0.000878      0.000096         0.001283        0.000699   \n",
       "3        0.000838      0.000093         0.001607        0.001447   \n",
       "4        0.000788      0.000074         0.000584        0.000038   \n",
       "5        0.002857      0.002874         0.000754        0.000124   \n",
       "6        0.000849      0.000064         0.001250        0.000682   \n",
       "7        0.000793      0.000048         0.000628        0.000002   \n",
       "8        0.000839      0.000083         0.001474        0.000929   \n",
       "9        0.001155      0.000655         0.001532        0.000998   \n",
       "10       0.000695      0.000008         0.000872        0.000421   \n",
       "11       0.000933      0.000183         0.000781        0.000179   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf  \\\n",
       "0                6                      1   \n",
       "1                6                      2   \n",
       "2                6                      3   \n",
       "3                6                      4   \n",
       "4                8                      1   \n",
       "5                8                      2   \n",
       "6                8                      3   \n",
       "7                8                      4   \n",
       "8               12                      1   \n",
       "9               12                      2   \n",
       "10              12                      3   \n",
       "11              12                      4   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "0    {'max_depth': 6, 'min_samples_leaf': 1}           0.278476   \n",
       "1    {'max_depth': 6, 'min_samples_leaf': 2}           0.289902   \n",
       "2    {'max_depth': 6, 'min_samples_leaf': 3}           0.363173   \n",
       "3    {'max_depth': 6, 'min_samples_leaf': 4}           0.498626   \n",
       "4    {'max_depth': 8, 'min_samples_leaf': 1}           0.279088   \n",
       "5    {'max_depth': 8, 'min_samples_leaf': 2}           0.300770   \n",
       "6    {'max_depth': 8, 'min_samples_leaf': 3}           0.442840   \n",
       "7    {'max_depth': 8, 'min_samples_leaf': 4}           0.498626   \n",
       "8   {'max_depth': 12, 'min_samples_leaf': 1}           0.293987   \n",
       "9   {'max_depth': 12, 'min_samples_leaf': 2}           0.281352   \n",
       "10  {'max_depth': 12, 'min_samples_leaf': 3}           0.442840   \n",
       "11  {'max_depth': 12, 'min_samples_leaf': 4}           0.483526   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           -0.129841           0.574093         0.240909        0.288605   \n",
       "1           -0.784817           0.617732         0.040939        0.599039   \n",
       "2           -0.528800           0.430428         0.088267        0.437195   \n",
       "3           -0.286714           0.213057         0.141656        0.324565   \n",
       "4           -0.872211           0.508381        -0.028248        0.604070   \n",
       "5           -0.785020           0.597665         0.037805        0.594316   \n",
       "6           -0.468052           0.436243         0.137011        0.427852   \n",
       "7           -0.286714           0.213057         0.141656        0.324565   \n",
       "8           -0.533830           0.520650         0.093602        0.453209   \n",
       "9           -0.785720           0.585089         0.026907        0.587841   \n",
       "10          -0.528800           0.436243         0.116761        0.456489   \n",
       "11          -0.286714           0.339900         0.178904        0.334422   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 9  \n",
       "2                 8  \n",
       "3                 3  \n",
       "4                12  \n",
       "5                10  \n",
       "6                 5  \n",
       "7                 4  \n",
       "8                 7  \n",
       "9                11  \n",
       "10                6  \n",
       "11                2  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe for results\n",
    "dt_df=pd.DataFrame(gs_dt.cv_results_)\n",
    "dt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5362ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24090947090929934 {'max_depth': 6, 'min_samples_leaf': 1}\n",
      "0.04093905594001479 {'max_depth': 6, 'min_samples_leaf': 2}\n",
      "0.08826691829056584 {'max_depth': 6, 'min_samples_leaf': 3}\n",
      "0.14165628064887137 {'max_depth': 6, 'min_samples_leaf': 4}\n",
      "-0.028247589651705447 {'max_depth': 8, 'min_samples_leaf': 1}\n",
      "0.037805354401777125 {'max_depth': 8, 'min_samples_leaf': 2}\n",
      "0.137010569165079 {'max_depth': 8, 'min_samples_leaf': 3}\n",
      "0.14165628064887134 {'max_depth': 8, 'min_samples_leaf': 4}\n",
      "0.09360225824721491 {'max_depth': 12, 'min_samples_leaf': 1}\n",
      "0.026907019355188317 {'max_depth': 12, 'min_samples_leaf': 2}\n",
      "0.11676115269578809 {'max_depth': 12, 'min_samples_leaf': 3}\n",
      "0.17890402392013385 {'max_depth': 12, 'min_samples_leaf': 4}\n"
     ]
    }
   ],
   "source": [
    "#printing the evaluation scores\n",
    "cvres_dt=gs_dt.cv_results_\n",
    "for mean_score, params in zip(cvres_dt['mean_test_score'], cvres_dt['params']):\n",
    "    print((mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab0ac4",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb7b6ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a Random forest instance\n",
    "rf=RandomForestRegressor()\n",
    "rf.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "820be326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.9342193481568827\n",
      "R2 Score of testing set 0.5601587703811616\n"
     ]
    }
   ],
   "source": [
    "#Printing the score of test and train set\n",
    "print(f'R2 Score of training set {rf.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set {rf.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f2dea4",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "365a574d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-16.65639952, -18.31898666, -13.4371411 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(rf, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3feda309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Random Forest Regressor is 0.46227001695270253\n",
      "The mean squared error of Random Forest Regressor is 24.638206292946744\n",
      "The mean absolute error of Random Forest Regressor is 14.88243317079537\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "rf_r2=np.mean(cross_val_score(rf, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Random Forest Regressor is {rf_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "rf_mse=np.mean(cross_val_score(rf, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "rf_rmse=np.sqrt(-(lrl_mse))\n",
    "print(f'The mean squared error of Random Forest Regressor is {rf_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "rf_mae=np.mean(cross_val_score(rf, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "rf_mae=(-(rf_mae))\n",
    "print(f'The mean absolute error of Random Forest Regressor is {rf_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0379afa4",
   "metadata": {},
   "source": [
    "#### Tuning the hyperparameters using Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1feb41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [3, 6],\n",
       "                          'n_estimators': [30, 60, 100]}],\n",
       "             return_train_score=True, scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [{'n_estimators':[30,60,100],\n",
    "              'max_features':[3,6]}]\n",
    "              #,{'bootstrap':[False], 'n_estimators':[3,10,100],\n",
    "              #'max_features':[4,6,8,10]}]\n",
    "gs_rf=GridSearchCV(rf, parameters, scoring='neg_mean_absolute_error',\n",
    "                   cv=5, return_train_score=True)\n",
    "gs_rf.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c31742c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 3, 'n_estimators': 60}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd9e4672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=3, n_estimators=60)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimator\n",
    "rf_b=gs_rf.best_estimator_\n",
    "rf_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3583b0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set after hyperpar tuining 0.9446113074005792\n",
      "R2 Score of testing set after hyperpar tuining  0.583514514053533\n"
     ]
    }
   ],
   "source": [
    "#Printing the score of test and train set\n",
    "rf_tr=rf_b.score(scaled_X_train, y_train)\n",
    "rf_te=rf_b.score(scaled_X_test, y_test)\n",
    "print(f'R2 Score of training set after hyperpar tuining {rf_tr}')\n",
    "print(f'R2 Score of testing set after hyperpar tuining  {rf_te}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aaf2aac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031320</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 30}</td>\n",
       "      <td>-15.206065</td>\n",
       "      <td>-17.147118</td>\n",
       "      <td>-14.651174</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.431028</td>\n",
       "      <td>3.987336</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.483819</td>\n",
       "      <td>-6.671857</td>\n",
       "      <td>-6.673937</td>\n",
       "      <td>-5.404667</td>\n",
       "      <td>-7.077190</td>\n",
       "      <td>-6.462294</td>\n",
       "      <td>0.563178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058334</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 60}</td>\n",
       "      <td>-15.946628</td>\n",
       "      <td>-14.458436</td>\n",
       "      <td>-13.399728</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.588132</td>\n",
       "      <td>3.214701</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.739682</td>\n",
       "      <td>-6.272814</td>\n",
       "      <td>-6.394061</td>\n",
       "      <td>-4.954404</td>\n",
       "      <td>-6.417995</td>\n",
       "      <td>-5.955791</td>\n",
       "      <td>0.557799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.094706</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 100}</td>\n",
       "      <td>-16.023651</td>\n",
       "      <td>-14.628984</td>\n",
       "      <td>-14.164291</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.630325</td>\n",
       "      <td>2.961266</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.898496</td>\n",
       "      <td>-6.226197</td>\n",
       "      <td>-6.186792</td>\n",
       "      <td>-5.315632</td>\n",
       "      <td>-6.189223</td>\n",
       "      <td>-5.963268</td>\n",
       "      <td>0.344609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 30}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017812</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 60}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.029066</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 100}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.031320      0.003125         0.002744        0.000701   \n",
       "1       0.058334      0.001916         0.004440        0.000498   \n",
       "2       0.094706      0.004154         0.006807        0.000394   \n",
       "3       0.010079      0.000535         0.000000        0.000000   \n",
       "4       0.017812      0.000680         0.000000        0.000000   \n",
       "5       0.029066      0.001438         0.000000        0.000000   \n",
       "\n",
       "  param_max_features param_n_estimators  \\\n",
       "0                  3                 30   \n",
       "1                  3                 60   \n",
       "2                  3                100   \n",
       "3                  6                 30   \n",
       "4                  6                 60   \n",
       "5                  6                100   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0   {'max_features': 3, 'n_estimators': 30}         -15.206065   \n",
       "1   {'max_features': 3, 'n_estimators': 60}         -15.946628   \n",
       "2  {'max_features': 3, 'n_estimators': 100}         -16.023651   \n",
       "3   {'max_features': 6, 'n_estimators': 30}                NaN   \n",
       "4   {'max_features': 6, 'n_estimators': 60}                NaN   \n",
       "5  {'max_features': 6, 'n_estimators': 100}                NaN   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0         -17.147118         -14.651174  ...       -15.431028        3.987336   \n",
       "1         -14.458436         -13.399728  ...       -14.588132        3.214701   \n",
       "2         -14.628984         -14.164291  ...       -14.630325        2.961266   \n",
       "3                NaN                NaN  ...              NaN             NaN   \n",
       "4                NaN                NaN  ...              NaN             NaN   \n",
       "5                NaN                NaN  ...              NaN             NaN   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                3           -6.483819           -6.671857   \n",
       "1                1           -5.739682           -6.272814   \n",
       "2                2           -5.898496           -6.226197   \n",
       "3                4                 NaN                 NaN   \n",
       "4                5                 NaN                 NaN   \n",
       "5                6                 NaN                 NaN   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0           -6.673937           -5.404667           -7.077190   \n",
       "1           -6.394061           -4.954404           -6.417995   \n",
       "2           -6.186792           -5.315632           -6.189223   \n",
       "3                 NaN                 NaN                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "5                 NaN                 NaN                 NaN   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0         -6.462294         0.563178  \n",
       "1         -5.955791         0.557799  \n",
       "2         -5.963268         0.344609  \n",
       "3               NaN              NaN  \n",
       "4               NaN              NaN  \n",
       "5               NaN              NaN  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe for results\n",
    "rf_df=pd.DataFrame(gs_rf.cv_results_)\n",
    "rf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "37586cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.431027701577898 {'max_features': 3, 'n_estimators': 30}\n",
      "14.588131644236881 {'max_features': 3, 'n_estimators': 60}\n",
      "14.630324763199756 {'max_features': 3, 'n_estimators': 100}\n",
      "nan {'max_features': 6, 'n_estimators': 30}\n",
      "nan {'max_features': 6, 'n_estimators': 60}\n",
      "nan {'max_features': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#printing the evaluation scores\n",
    "cvres=gs_rf.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print((-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afc719",
   "metadata": {},
   "source": [
    "### Important scores of each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c54bf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4049302810916229, 'Age_Group'),\n",
       " (0.2541610395264388, 'O3 AQI_mean'),\n",
       " (0.20408693259646274, 'O3 AQI_max'),\n",
       " (0.13682174678547554, 'O3 AQI_min')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances=rf_b.feature_importances_\n",
    "col=X.columns\n",
    "sorted(zip(feature_importances, col), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb742e4",
   "metadata": {},
   "source": [
    "## Predicting on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1eb46580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model in test data\n",
    "y_pred_lr=lr.predict(scaled_X_test)     #linear \n",
    "y_pred_lrl=lrl.predict(scaled_X_test)   #lasso\n",
    "y_pred_lrr=lrr.predict(scaled_X_test)   #Ridge\n",
    "y_pred_svm=svm.predict(scaled_X_test)   #svm\n",
    "y_pred_dt=dt_b.predict(scaled_X_test)   #Dicision tree\n",
    "y_pred_rf=rf_b.predict(scaled_X_test)   #Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d6b33",
   "metadata": {},
   "source": [
    "### R2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8f87af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2_score of linear regression is 0.4373255461236534\n",
      "The r2_score of lasso regression is 0.28237914152090693\n",
      "The r2_score of Ridge regression is 0.3018575249435965\n",
      "The r2_score of SVM regression is 0.04357863482048252\n",
      "The r2_score of decision tree regression is 0.4099796597112151\n",
      "The r2_score of random forest regression is 0.583514514053533\n"
     ]
    }
   ],
   "source": [
    "#regression matrices-mean absolute error(give you the prediction error)\n",
    "lin_r2_lr=r2_score(y_test, y_pred_lr)\n",
    "print(f'The r2_score of linear regression is {lin_r2_lr}')\n",
    "\n",
    "lin_r2_lrl=r2_score(y_test, y_pred_lrl)\n",
    "print(f'The r2_score of lasso regression is {lin_r2_lrl}')\n",
    "\n",
    "lin_r2_lrr=r2_score(y_test, y_pred_lrr)\n",
    "print(f'The r2_score of Ridge regression is {lin_r2_lrr}')\n",
    "\n",
    "lin_r2_svm=r2_score(y_test, y_pred_svm)\n",
    "print(f'The r2_score of SVM regression is {lin_r2_svm}')\n",
    "\n",
    "lin_r2_dt=r2_score(y_test, y_pred_dt)\n",
    "print(f'The r2_score of decision tree regression is {lin_r2_dt}')\n",
    "\n",
    "lin_r2_rf=r2_score(y_test, y_pred_rf)\n",
    "print(f'The r2_score of random forest regression is {lin_r2_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d3430a",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f769b817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absoulte error of linear regression is 19.391147505256715\n",
      "The mean absoulte error of lasso regression is 22.30432768732225\n",
      "The mean absoulte error of Ridge regression is 23.093487458548214\n",
      "The mean absoulte error of SVM regression is 25.42408038181008\n",
      "The mean absoulte error of decision tree regression is 17.70962447705933\n",
      "The mean absoulte error of random forest regression is 16.90097045792648\n"
     ]
    }
   ],
   "source": [
    "#regression matrices-mean absolute error(give you the prediction error)\n",
    "lin_mae_lr=mean_absolute_error(y_test, y_pred_lr)\n",
    "print(f'The mean absoulte error of linear regression is {lin_mae_lr}')\n",
    "\n",
    "lin_mae_lrl=mean_absolute_error(y_test, y_pred_lrl)\n",
    "print(f'The mean absoulte error of lasso regression is {lin_mae_lrl}')\n",
    "\n",
    "lin_mae_lrr=mean_absolute_error(y_test, y_pred_lrr)\n",
    "print(f'The mean absoulte error of Ridge regression is {lin_mae_lrr}')\n",
    "\n",
    "lin_mae_svm=mean_absolute_error(y_test, y_pred_svm)\n",
    "print(f'The mean absoulte error of SVM regression is {lin_mae_svm}')\n",
    "\n",
    "lin_mae_dt=mean_absolute_error(y_test, y_pred_dt)\n",
    "print(f'The mean absoulte error of decision tree regression is {lin_mae_dt}')\n",
    "\n",
    "lin_mae_rf=mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f'The mean absoulte error of random forest regression is {lin_mae_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b689f8",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "79de55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error of linear regression is 27.22371558333459\n",
      "The mean squared error of lasso regression is 30.74442156940809\n",
      "The mean squared error of ridge regression is 30.324303211972286\n",
      "The mean squared error of SVM regression is 35.493059275795524\n",
      "The mean squared error of decision tree regression is 27.877401608923247\n",
      "The mean squared error of random forest regression is 23.421717340406506\n"
     ]
    }
   ],
   "source": [
    "#regression matrices-mean squared error(give you the prediction error)\n",
    "lin_mse_lr=mean_squared_error(y_test, y_pred_lr)\n",
    "lin_rmse_lr=np.sqrt(lin_mse_lr)\n",
    "print(f'The mean squared error of linear regression is {lin_rmse_lr}')\n",
    "\n",
    "lin_mse_lrl=mean_squared_error(y_test, y_pred_lrl)\n",
    "lin_rmse_lrl=np.sqrt(lin_mse_lrl)\n",
    "print(f'The mean squared error of lasso regression is {lin_rmse_lrl}')\n",
    "\n",
    "lin_mse_lrr=mean_squared_error(y_test, y_pred_lrr)\n",
    "lin_rmse_lrr=np.sqrt(lin_mse_lrr)\n",
    "print(f'The mean squared error of ridge regression is {lin_rmse_lrr}')\n",
    "\n",
    "lin_mse_svm=mean_squared_error(y_test, y_pred_svm)\n",
    "lin_rmse_svm=np.sqrt(lin_mse_svm)\n",
    "print(f'The mean squared error of SVM regression is {lin_rmse_svm}')\n",
    "\n",
    "lin_mse_dt=mean_squared_error(y_test, y_pred_dt)\n",
    "lin_rmse_dt=np.sqrt(lin_mse_dt)\n",
    "print(f'The mean squared error of decision tree regression is {lin_rmse_dt}')\n",
    "\n",
    "lin_mse_rf=mean_squared_error(y_test, y_pred_rf)\n",
    "lin_rmse_rf=np.sqrt(lin_mse_rf)\n",
    "print(f'The mean squared error of random forest regression is {lin_rmse_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db51d86",
   "metadata": {},
   "source": [
    "### Actual and predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d01a910c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value of Age_Adjusted_Rate</th>\n",
       "      <th>Random Forest Predicted Age_Adjusted_Rate</th>\n",
       "      <th>Linear Reg Predicted Age_Adjusted_Rate</th>\n",
       "      <th>Lasso Reg Predicted Age_Adjusted_Rate</th>\n",
       "      <th>Ridge Reg Predicted Age_Adjusted_Rate</th>\n",
       "      <th>Decesion Tree Predicted Age_Adjusted_Rate</th>\n",
       "      <th>SVM Predicted Age_Adjusted_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.005882</td>\n",
       "      <td>51.998182</td>\n",
       "      <td>46.642998</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.555552</td>\n",
       "      <td>53.725838</td>\n",
       "      <td>32.503276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.950000</td>\n",
       "      <td>105.019084</td>\n",
       "      <td>84.324619</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>81.729036</td>\n",
       "      <td>131.726471</td>\n",
       "      <td>64.650190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.825000</td>\n",
       "      <td>47.854675</td>\n",
       "      <td>45.219743</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.196745</td>\n",
       "      <td>63.265116</td>\n",
       "      <td>39.014877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.671053</td>\n",
       "      <td>91.870791</td>\n",
       "      <td>87.489405</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>82.328058</td>\n",
       "      <td>93.708807</td>\n",
       "      <td>55.977383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.936111</td>\n",
       "      <td>73.429084</td>\n",
       "      <td>87.962298</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>82.315633</td>\n",
       "      <td>64.113587</td>\n",
       "      <td>59.172557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143.500000</td>\n",
       "      <td>81.809646</td>\n",
       "      <td>84.522772</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>81.516654</td>\n",
       "      <td>79.047187</td>\n",
       "      <td>65.720911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62.400000</td>\n",
       "      <td>66.658018</td>\n",
       "      <td>86.542415</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>81.709667</td>\n",
       "      <td>64.073333</td>\n",
       "      <td>61.919234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90.216279</td>\n",
       "      <td>105.136332</td>\n",
       "      <td>85.973013</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>81.753325</td>\n",
       "      <td>86.887234</td>\n",
       "      <td>67.781317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.738760</td>\n",
       "      <td>38.747719</td>\n",
       "      <td>46.845702</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.401915</td>\n",
       "      <td>53.725838</td>\n",
       "      <td>34.840290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.506522</td>\n",
       "      <td>52.167931</td>\n",
       "      <td>48.429835</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.759932</td>\n",
       "      <td>53.652273</td>\n",
       "      <td>28.611913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57.374545</td>\n",
       "      <td>45.689629</td>\n",
       "      <td>47.363993</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.271737</td>\n",
       "      <td>52.947983</td>\n",
       "      <td>42.729545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88.020690</td>\n",
       "      <td>83.645955</td>\n",
       "      <td>85.747874</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>82.087843</td>\n",
       "      <td>79.047187</td>\n",
       "      <td>58.138590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42.800000</td>\n",
       "      <td>51.602305</td>\n",
       "      <td>48.846738</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.595347</td>\n",
       "      <td>44.352174</td>\n",
       "      <td>32.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82.608108</td>\n",
       "      <td>70.469553</td>\n",
       "      <td>85.381307</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>81.645383</td>\n",
       "      <td>64.073333</td>\n",
       "      <td>60.651349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>62.610145</td>\n",
       "      <td>80.772675</td>\n",
       "      <td>87.449999</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>82.040100</td>\n",
       "      <td>79.047187</td>\n",
       "      <td>60.936977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.602778</td>\n",
       "      <td>54.294496</td>\n",
       "      <td>48.162157</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.848512</td>\n",
       "      <td>56.640682</td>\n",
       "      <td>32.882078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30.440426</td>\n",
       "      <td>38.818212</td>\n",
       "      <td>46.060534</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.849932</td>\n",
       "      <td>38.578682</td>\n",
       "      <td>29.086585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>148.270588</td>\n",
       "      <td>111.618282</td>\n",
       "      <td>87.874886</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>82.305455</td>\n",
       "      <td>65.767925</td>\n",
       "      <td>62.452813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24.567949</td>\n",
       "      <td>42.057013</td>\n",
       "      <td>45.090211</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.544864</td>\n",
       "      <td>38.578682</td>\n",
       "      <td>33.180086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>68.427273</td>\n",
       "      <td>45.111028</td>\n",
       "      <td>45.834119</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>29.453897</td>\n",
       "      <td>53.725838</td>\n",
       "      <td>32.590425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30.086667</td>\n",
       "      <td>37.884040</td>\n",
       "      <td>42.579302</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>28.433037</td>\n",
       "      <td>33.133333</td>\n",
       "      <td>43.525723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Value of Age_Adjusted_Rate  \\\n",
       "0                           46.005882   \n",
       "1                          142.950000   \n",
       "2                           52.825000   \n",
       "3                           42.671053   \n",
       "4                           95.936111   \n",
       "5                          143.500000   \n",
       "6                           62.400000   \n",
       "7                           90.216279   \n",
       "8                           38.738760   \n",
       "9                           55.506522   \n",
       "10                          57.374545   \n",
       "11                          88.020690   \n",
       "12                          42.800000   \n",
       "13                          82.608108   \n",
       "14                          62.610145   \n",
       "15                          55.602778   \n",
       "16                          30.440426   \n",
       "17                         148.270588   \n",
       "18                          24.567949   \n",
       "19                          68.427273   \n",
       "20                          30.086667   \n",
       "\n",
       "    Random Forest Predicted Age_Adjusted_Rate  \\\n",
       "0                                   51.998182   \n",
       "1                                  105.019084   \n",
       "2                                   47.854675   \n",
       "3                                   91.870791   \n",
       "4                                   73.429084   \n",
       "5                                   81.809646   \n",
       "6                                   66.658018   \n",
       "7                                  105.136332   \n",
       "8                                   38.747719   \n",
       "9                                   52.167931   \n",
       "10                                  45.689629   \n",
       "11                                  83.645955   \n",
       "12                                  51.602305   \n",
       "13                                  70.469553   \n",
       "14                                  80.772675   \n",
       "15                                  54.294496   \n",
       "16                                  38.818212   \n",
       "17                                 111.618282   \n",
       "18                                  42.057013   \n",
       "19                                  45.111028   \n",
       "20                                  37.884040   \n",
       "\n",
       "    Linear Reg Predicted Age_Adjusted_Rate  \\\n",
       "0                                46.642998   \n",
       "1                                84.324619   \n",
       "2                                45.219743   \n",
       "3                                87.489405   \n",
       "4                                87.962298   \n",
       "5                                84.522772   \n",
       "6                                86.542415   \n",
       "7                                85.973013   \n",
       "8                                46.845702   \n",
       "9                                48.429835   \n",
       "10                               47.363993   \n",
       "11                               85.747874   \n",
       "12                               48.846738   \n",
       "13                               85.381307   \n",
       "14                               87.449999   \n",
       "15                               48.162157   \n",
       "16                               46.060534   \n",
       "17                               87.874886   \n",
       "18                               45.090211   \n",
       "19                               45.834119   \n",
       "20                               42.579302   \n",
       "\n",
       "    Lasso Reg Predicted Age_Adjusted_Rate  \\\n",
       "0                               56.997428   \n",
       "1                               75.909883   \n",
       "2                               56.997428   \n",
       "3                               75.909883   \n",
       "4                               75.909883   \n",
       "5                               75.909883   \n",
       "6                               75.909883   \n",
       "7                               75.909883   \n",
       "8                               56.997428   \n",
       "9                               56.997428   \n",
       "10                              56.997428   \n",
       "11                              75.909883   \n",
       "12                              56.997428   \n",
       "13                              75.909883   \n",
       "14                              75.909883   \n",
       "15                              56.997428   \n",
       "16                              56.997428   \n",
       "17                              75.909883   \n",
       "18                              56.997428   \n",
       "19                              56.997428   \n",
       "20                              56.997428   \n",
       "\n",
       "    Ridge Reg Predicted Age_Adjusted_Rate  \\\n",
       "0                               29.555552   \n",
       "1                               81.729036   \n",
       "2                               29.196745   \n",
       "3                               82.328058   \n",
       "4                               82.315633   \n",
       "5                               81.516654   \n",
       "6                               81.709667   \n",
       "7                               81.753325   \n",
       "8                               29.401915   \n",
       "9                               29.759932   \n",
       "10                              29.271737   \n",
       "11                              82.087843   \n",
       "12                              29.595347   \n",
       "13                              81.645383   \n",
       "14                              82.040100   \n",
       "15                              29.848512   \n",
       "16                              29.849932   \n",
       "17                              82.305455   \n",
       "18                              29.544864   \n",
       "19                              29.453897   \n",
       "20                              28.433037   \n",
       "\n",
       "    Decesion Tree Predicted Age_Adjusted_Rate  SVM Predicted Age_Adjusted_Rate  \n",
       "0                                   53.725838                        32.503276  \n",
       "1                                  131.726471                        64.650190  \n",
       "2                                   63.265116                        39.014877  \n",
       "3                                   93.708807                        55.977383  \n",
       "4                                   64.113587                        59.172557  \n",
       "5                                   79.047187                        65.720911  \n",
       "6                                   64.073333                        61.919234  \n",
       "7                                   86.887234                        67.781317  \n",
       "8                                   53.725838                        34.840290  \n",
       "9                                   53.652273                        28.611913  \n",
       "10                                  52.947983                        42.729545  \n",
       "11                                  79.047187                        58.138590  \n",
       "12                                  44.352174                        32.002015  \n",
       "13                                  64.073333                        60.651349  \n",
       "14                                  79.047187                        60.936977  \n",
       "15                                  56.640682                        32.882078  \n",
       "16                                  38.578682                        29.086585  \n",
       "17                                  65.767925                        62.452813  \n",
       "18                                  38.578682                        33.180086  \n",
       "19                                  53.725838                        32.590425  \n",
       "20                                  33.133333                        43.525723  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual and predicated value of house using our best model\n",
    "house_value=pd.DataFrame({'Actual Value of Age_Adjusted_Rate':y_test, \n",
    "                'Random Forest Predicted Age_Adjusted_Rate':y_pred_rf,\n",
    "                'Linear Reg Predicted Age_Adjusted_Rate':y_pred_lr,\n",
    "                'Lasso Reg Predicted Age_Adjusted_Rate':y_pred_lrl,\n",
    "                'Ridge Reg Predicted Age_Adjusted_Rate':y_pred_lrr,       \n",
    "                'Decesion Tree Predicted Age_Adjusted_Rate':y_pred_dt,\n",
    "                 'SVM Predicted Age_Adjusted_Rate':y_pred_svm})\n",
    "house_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da306ccc",
   "metadata": {},
   "source": [
    "## Evaluation metrices of differnt models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "315c79e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Reg</th>\n",
       "      <th>Lasso Reg</th>\n",
       "      <th>Ridge Reg</th>\n",
       "      <th>SVM Reg</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.437326</td>\n",
       "      <td>0.282379</td>\n",
       "      <td>0.301858</td>\n",
       "      <td>0.043579</td>\n",
       "      <td>0.409980</td>\n",
       "      <td>0.583515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>19.391148</td>\n",
       "      <td>22.304328</td>\n",
       "      <td>23.093487</td>\n",
       "      <td>25.424080</td>\n",
       "      <td>17.709624</td>\n",
       "      <td>16.900970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <td>27.223716</td>\n",
       "      <td>30.744422</td>\n",
       "      <td>30.324303</td>\n",
       "      <td>35.493059</td>\n",
       "      <td>27.877402</td>\n",
       "      <td>23.421717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Linear Reg  Lasso Reg  Ridge Reg    SVM Reg  \\\n",
       "R2                         0.437326   0.282379   0.301858   0.043579   \n",
       "Mean Absolute Error       19.391148  22.304328  23.093487  25.424080   \n",
       "Root Mean Squared Error   27.223716  30.744422  30.324303  35.493059   \n",
       "\n",
       "                         Decision Tree  Random Forest  \n",
       "R2                            0.409980       0.583515  \n",
       "Mean Absolute Error          17.709624      16.900970  \n",
       "Root Mean Squared Error      27.877402      23.421717  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe on evaluation metrices\n",
    "evaluation_df=pd.DataFrame({'Linear Reg':[lin_r2_lr,lin_mae_lr,lin_rmse_lr],\n",
    "                           'Lasso Reg':[lin_r2_lrl,lin_mae_lrl,lin_rmse_lrl],\n",
    "                            'Ridge Reg':[lin_r2_lrr,lin_mae_lrr,lin_rmse_lrr],\n",
    "                            'SVM Reg':[lin_r2_svm,lin_mae_svm,lin_rmse_svm],\n",
    "                           'Decision Tree':[lin_r2_dt,lin_mae_dt,lin_rmse_dt],\n",
    "                            'Random Forest':[lin_r2_rf,lin_mae_rf,lin_rmse_rf]}\n",
    "                           ,index=['R2','Mean Absolute Error',\n",
    "                                    'Root Mean Squared Error'])\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17ce19",
   "metadata": {},
   "source": [
    "## Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea584061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_asthma.pkl']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_b, 'model_asthma.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "398e9216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_asthma.pkl']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving standard scaler\n",
    "joblib.dump(std_scaler, 'scaler_asthma.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97731aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

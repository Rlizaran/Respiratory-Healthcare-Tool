{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae3416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from matplotlib import rcParams\n",
    "#importing sklearn models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef5099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d333ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining data path\n",
    "data_path=Path('resources/Cleaned_folder/aqi_asthma.csv')\n",
    "# Reading data source using pandas\n",
    "asthma_df=pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0927bea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                                  int64\n",
       "Age_Group                             int64\n",
       "county                               object\n",
       "Number_of_Asthma_ED_Visits          float64\n",
       "Age_Adjusted_Rate_of_Asthma_ED_V    float64\n",
       "NO2 AQI_mean                        float64\n",
       "NO2 AQI_max                         float64\n",
       "NO2 AQI_min                         float64\n",
       "O3 AQI_mean                         float64\n",
       "O3 AQI_max                          float64\n",
       "O3 AQI_min                          float64\n",
       "SO2 AQI_mean                        float64\n",
       "SO2 AQI_max                         float64\n",
       "SO2 AQI_min                         float64\n",
       "CO AQI_mean                         float64\n",
       "CO AQI_max                          float64\n",
       "CO AQI_min                          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asthma_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a9584bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature matrix (X)\n",
    "#selecting all columns except 'Age-adjusted-rate'\n",
    "X=asthma_df.drop(['Age_Adjusted_Rate_of_Asthma_ED_V','county'], axis=1) \n",
    "\n",
    "# create response vector (y)\n",
    "##selecting 'Age-adjusted-rate'\n",
    "y=asthma_df['Age_Adjusted_Rate_of_Asthma_ED_V'].values  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e619e1c",
   "metadata": {},
   "source": [
    "#### Splitting data in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d849489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set**: Used to train the classifier.\n",
    "#Testing set**: Used to estimate the error rate of the trained classifier.\n",
    "#Also using train_index and test_index to get train and test data index \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                               X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a0ab691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train=(83, 15)\n",
      "Shape of X_test=(21, 15)\n",
      "Shape of y_train=(83,)\n",
      "Shape of X_test=(21,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of X_train={X_train.shape}')\n",
    "print(f'Shape of X_test={X_test.shape}')\n",
    "print(f'Shape of y_train={y_train.shape}')\n",
    "print(f'Shape of X_test={y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae03b8b",
   "metadata": {},
   "source": [
    "#### Scaling using standard scaler on feature matrix (X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59ca8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Different columns have differnt scale so standrazied it \n",
    "#features scaling using standard scaler on x only\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std_scaler=StandardScaler()\n",
    "scaled_X_train=std_scaler.fit_transform(X_train)\n",
    "scaled_X_test=std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d4b650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 15)\n",
      "(104,)\n"
     ]
    }
   ],
   "source": [
    "#shape of the X and y\n",
    "print(scaled_X_train.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbc52c",
   "metadata": {},
   "source": [
    "### Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb62448",
   "metadata": {},
   "source": [
    "To evaluate a model, we also need an **evaluation metric:**\n",
    "\n",
    "- A numeric calculation used to **quantify** the performance of a model.\n",
    "- The appropriate metric depends on the **goals** of your problem.\n",
    "\n",
    "The most common choices for regression problems are:\n",
    "\n",
    "- **R-squared**: The percentage of variation explained by the model (a \"reward function,\" as higher is better).\n",
    "- **Mean squared error**: The average squared distance between the prediction and the correct answer (a \"loss function,\" as lower is better).\n",
    "- **Mean absolute error**: The average absolute distance between the prediction and the correct answer (a \"loss function,\" as lower is better).\n",
    "\n",
    "In this case, we'll use mean squared error, R2, and mean absolute error because it is more interpretable in a predictive context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e8d5b",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cf35236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using linear regression\n",
    "# Make a linear regression instance\n",
    "lr=LinearRegression()\n",
    "# Training the model on the data, storing the information learned from the data\n",
    "# Model is learning the relationship between X and y \n",
    "lr.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d8ee5aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.8187233825511082\n",
      "R2 Score of testing  set  0.8590207162163466\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {lr.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing  set  {lr.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da321253",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds.\n",
    "-  Cross valiation allows the training set into distinct subsets called folds.\n",
    "- A model is trained using k-1 of the folds as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d9bffa8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.18150373, -13.01962261, -14.08140065, -14.40623236,\n",
       "       -12.7821553 ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc53cf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Linear Regression is 0.48817169182285447\n",
      "The mean squared error of Linear Regression is 16.85909268459506\n",
      "The mean absolute error of Linear Regression is 13.294182929913623\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lr_r2=np.mean(cross_val_score(lr, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Linear Regression is {lr_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lr_mse=np.mean(cross_val_score(lr, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lr_rmse=np.sqrt(-(lr_mse))\n",
    "print(f'The mean squared error of Linear Regression is {lr_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lr_mae=np.mean(cross_val_score(lr, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lr_mae=(-(lr_mae))\n",
    "print(f'The mean absolute error of Linear Regression is {lr_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f390e4",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "56dbafca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using ridge regression(ridge make some features going to near zero)\n",
    "#alpha=0 no regularization( all features are used)\n",
    "# Make a ridge regression instance\n",
    "lr_r=Ridge()\n",
    "lr_r.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8c1c63a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.814320407949326\n",
      "R2 Score of testing set  0.8647024989632942\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {lr_r.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {lr_r.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d917074",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc70cc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.26694862, -13.02570106, -15.81391099])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr_r, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4be8990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Ridge Regression is 0.5190225440234283\n",
      "The mean squared error of Ridge Regression is 16.67797198033198\n",
      "The mean absolute error of Ridge Regression is 12.573961515804765\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lr_r_r2=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Ridge Regression is {lr_r_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lr_r_mse=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lr_r_rmse=np.sqrt(-(lr_r_mse))\n",
    "print(f'The mean squared error of Ridge Regression is {lr_r_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lr_r_mae=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lr_r_mae=(-(lr_r_mae))\n",
    "print(f'The mean absolute error of Ridge Regression is {lr_r_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5b0d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#choosing the best alpha\n",
    "alpha=[]\n",
    "error=[]\n",
    "for i in range(1,1000,50):\n",
    "    alpha.append(i/10)\n",
    "    lrr=Ridge(alpha=(i/10))\n",
    "    error.append(np.mean(cross_val_score(lrr, scaled_X_train, y_train, scoring='neg_mean_absolute_error',\n",
    "                                         cv=5)))\n",
    "plt.plot(alpha,error) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4951f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing the best alpha (look figure where alpha start to saturate)\n",
    "lrr=Ridge(alpha=10)\n",
    "lrr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f081208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set with alpha 40 -4369.043902778573\n",
      "R2 Score of testing set with alpha 40 -3041.1788073850216\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set \n",
    "print(f'R2 Score of training set with alpha 40 {lrr.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set with alpha 40 {lrr.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f373da",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69e9d466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.26694862, -13.02570106, -15.81391099])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr_r, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d20b56ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Ridge Regression with alpha 10 is 0.5538084409345555\n",
      "The mean squared error of Ridge Regression with alpha 10 is 16.67797198033198\n",
      "The mean absolute error of Ridge Regression with alpha 10 is 12.573961515804765\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lrr_r2=np.mean(cross_val_score(lrr, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Ridge Regression with alpha 10 is {lrr_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lrr_mse=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lrr_rmse=np.sqrt(-(lrr_mse))\n",
    "print(f'The mean squared error of Ridge Regression with alpha 10 is {lrr_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lrr_mae=np.mean(cross_val_score(lr_r, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lrr_mae=(-(lrr_mae))\n",
    "print(f'The mean absolute error of Ridge Regression with alpha 10 is {lrr_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6058a94",
   "metadata": {},
   "source": [
    "## Laso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28bcfe0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using lassoregression(lasso make some features going to exactly zero)\n",
    "#alpha=0 no regularization( all features are used)\n",
    "# Make a lasso regression instance\n",
    "lr_l=Lasso()\n",
    "lr_l.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab17e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.7488283842876851\n",
      "R2 Score of testing set  0.7701611905503272\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {lr_l.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {lr_l.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842638a2",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0effb939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.80297702, -13.94631581, -12.85551078])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr_l, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1237e404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Lasso Regression is 0.6329144771147857\n",
      "The mean squared error of Lasso Regression is 17.601576254338745\n",
      "The mean absolute error of Lasso Regression is 12.521245242774901\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lr_l_r2=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=2))\n",
    "print(f'The R2 of Lasso Regression is {lr_l_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lr_l_mse=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lr_l_rmse=np.sqrt(-(lr_l_mse))\n",
    "print(f'The mean squared error of Lasso Regression is {lr_l_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lr_l_mae=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lr_l_mae=(-(lr_l_mae))\n",
    "print(f'The mean absolute error of Lasso Regression is {lr_l_mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18aaa374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#choosing the best alpha\n",
    "alpha=[]\n",
    "error=[]\n",
    "for i in range(1,100,10):\n",
    "    alpha.append(i/10)\n",
    "    lrl=Lasso(alpha=(i/10))\n",
    "    error.append(np.mean(cross_val_score(lrl, scaled_X_train, y_train, scoring='neg_mean_absolute_error',\n",
    "                                         cv=5)))\n",
    "plt.plot(alpha,error) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ffaae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#choosing the best alpha\n",
    "lrl=Lasso(alpha=10)\n",
    "lrl.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20b8b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set with alpha 10 0.30267850496357285\n",
      "R2 Score of testing set with alpha 10 0.28237914152090693\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set \n",
    "print(f'R2 Score of training set with alpha 10 {lrl.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set with alpha 10 {lrl.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6002558",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cec426fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.80297702, -13.94631581, -12.85551078])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(lr_l, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73ee7b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Lasso Regression with alpha 10 is 0.19788197709315403\n",
      "The mean squared error of Lasso Regression with alpha 10 is 17.601576254338745\n",
      "The mean absolute error of Lasso Regressionwith alpha 10 is 12.521245242774901\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "lrl_r2=np.mean(cross_val_score(lrl, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Lasso Regression with alpha 10 is {lrl_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "lrl_mse=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "lrl_rmse=np.sqrt(-(lrl_mse))\n",
    "print(f'The mean squared error of Lasso Regression with alpha 10 is {lrl_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "lrl_mae=np.mean(cross_val_score(lr_l, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "lrl_mae=(-(lrl_mae))\n",
    "print(f'The mean absolute error of Lasso Regressionwith alpha 10 is {lrl_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b4d79",
   "metadata": {},
   "source": [
    "## Support Vector Machine(SVM) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "972957f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(epsilon=1.5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a svm regression instance\n",
    "svm=LinearSVR(epsilon=1.5)\n",
    "svm.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83b8b8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.39508206437493754\n",
      "R2 Score of testing set  0.4497650118953762\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {svm.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {svm.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ac1731",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96070d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-28.38869445, -22.81243913, -32.6465356 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(svm, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0129d264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of svm Regression is -0.2497625712795674\n",
      "The mean squared error of svm Regression is 31.262314160824626\n",
      "The mean absolute error of svm Regression is 22.804066594286144\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "svm_r2=np.mean(cross_val_score(svm, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of svm Regression is {svm_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "svm_mse=np.mean(cross_val_score(svm, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "svm_rmse=np.sqrt(-(svm_mse))\n",
    "print(f'The mean squared error of svm Regression is {svm_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "svm_mae=np.mean(cross_val_score(svm, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "svm_mae=(-(svm_mae))\n",
    "print(f'The mean absolute error of svm Regression is {svm_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a08892",
   "metadata": {},
   "source": [
    "## Support Vector Machine(SVR) Kernel Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a577e349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a svm regression instance\n",
    "svr=SVR(kernel='linear')\n",
    "svr.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ae46ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.6560044126021761\n",
      "R2 Score of testing set  0.6971531026611963\n"
     ]
    }
   ],
   "source": [
    "#Printing the R2 score of test and train set\n",
    "print(f'R2 Score of training set {svr.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {svr.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2adc541",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f2165a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-14.45240362, -16.08003476, -15.26700429])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(svr, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b20259d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of svr is 0.5139168530443536\n",
      "The mean squared error of svr is 21.14974312582804\n",
      "The mean absolute error of svr  is 14.799399460341936\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "svr_r2=np.mean(cross_val_score(svr, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of svr is {svr_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "svr_mse=np.mean(cross_val_score(svr, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "svr_rmse=np.sqrt(-(svr_mse))\n",
    "print(f'The mean squared error of svr is {svr_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "svr_mae=np.mean(cross_val_score(svr, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "svr_mae=(-(svr_mae))\n",
    "print(f'The mean absolute error of svr  is {svr_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a433f",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16ce2892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a decision tree instance\n",
    "dt=DecisionTreeRegressor()\n",
    "dt.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "203f961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 1.0\n",
      "R2 Score of testing set  0.7839349437476085\n"
     ]
    }
   ],
   "source": [
    "#Printing the score of test and train set\n",
    "print(f'R2 Score of training set {dt.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set  {dt.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5079ab",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "197a86ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.59084624, -15.54323722, -17.91830322])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(dt, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a1b676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Decision Tree Regressor is 0.5953934829548357\n",
      "The mean squared error of Decision Tree Regressor is 17.650669643207003\n",
      "The mean absolute error of Decision Tree Regressor is 12.144976507373887\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "dt_r2=np.mean(cross_val_score(dt, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Decision Tree Regressor is {dt_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "dt_mse=np.mean(cross_val_score(dt, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "dt_rmse=np.sqrt(-(dt_mse))\n",
    "print(f'The mean squared error of Decision Tree Regressor is {dt_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "dt_mae=np.mean(cross_val_score(dt, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "dt_mae=(-(dt_mae))\n",
    "print(f'The mean absolute error of Decision Tree Regressor is {dt_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df43df9c",
   "metadata": {},
   "source": [
    "### Tuning hyperparamaters  using Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a0adfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 8, 12],\n",
       "                         'min_samples_leaf': range(1, 5)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "              'max_depth':[6, 8,12],\n",
    "              'min_samples_leaf':range(1,5)}\n",
    "gs_dt=GridSearchCV(dt, param_grid=parameters, \n",
    "                    cv=3, verbose=1, n_jobs=-1)\n",
    "gs_dt.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a16726a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 12, 'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "gs_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f248d449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=12, min_samples_leaf=3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimator\n",
    "dt_b=gs_dt.best_estimator_\n",
    "dt_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c524b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set after hyperpar tuining 0.9613499441459871\n",
      "R2 Score of testing set after hyperpar tuining  0.7905140960979169\n"
     ]
    }
   ],
   "source": [
    "#Printing the score of test and train set\n",
    "dt_tr=dt_b.score(scaled_X_train, y_train)\n",
    "dt_te=dt_b.score(scaled_X_test, y_test)\n",
    "print(f'R2 Score of training set after hyperpar tuining {dt_tr}')\n",
    "print(f'R2 Score of testing set after hyperpar tuining  {dt_te}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "759d24f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.650560</td>\n",
       "      <td>0.454518</td>\n",
       "      <td>0.443423</td>\n",
       "      <td>0.516167</td>\n",
       "      <td>0.095138</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>0.601175</td>\n",
       "      <td>0.385572</td>\n",
       "      <td>0.530798</td>\n",
       "      <td>0.102707</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.711139</td>\n",
       "      <td>0.554121</td>\n",
       "      <td>0.643152</td>\n",
       "      <td>0.636137</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_leaf': 4}</td>\n",
       "      <td>0.653774</td>\n",
       "      <td>0.554138</td>\n",
       "      <td>0.759628</td>\n",
       "      <td>0.655847</td>\n",
       "      <td>0.083904</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000766</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001420</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.665404</td>\n",
       "      <td>0.483661</td>\n",
       "      <td>0.594600</td>\n",
       "      <td>0.581222</td>\n",
       "      <td>0.074797</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.606669</td>\n",
       "      <td>0.536091</td>\n",
       "      <td>0.620258</td>\n",
       "      <td>0.587673</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.711139</td>\n",
       "      <td>0.556304</td>\n",
       "      <td>0.643152</td>\n",
       "      <td>0.636865</td>\n",
       "      <td>0.063367</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 8, 'min_samples_leaf': 4}</td>\n",
       "      <td>0.653774</td>\n",
       "      <td>0.554138</td>\n",
       "      <td>0.767558</td>\n",
       "      <td>0.658490</td>\n",
       "      <td>0.087192</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.653402</td>\n",
       "      <td>0.461075</td>\n",
       "      <td>0.523088</td>\n",
       "      <td>0.545855</td>\n",
       "      <td>0.080151</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.606521</td>\n",
       "      <td>0.464592</td>\n",
       "      <td>0.575129</td>\n",
       "      <td>0.548747</td>\n",
       "      <td>0.060871</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.711139</td>\n",
       "      <td>0.566318</td>\n",
       "      <td>0.722725</td>\n",
       "      <td>0.666727</td>\n",
       "      <td>0.071158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 12, 'min_samples_leaf': 4}</td>\n",
       "      <td>0.653774</td>\n",
       "      <td>0.554138</td>\n",
       "      <td>0.759628</td>\n",
       "      <td>0.655847</td>\n",
       "      <td>0.083904</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.000893      0.000022         0.000517        0.000002   \n",
       "1        0.000896      0.000027         0.000547        0.000023   \n",
       "2        0.000711      0.000071         0.000454        0.000064   \n",
       "3        0.000688      0.000031         0.000468        0.000003   \n",
       "4        0.000766      0.000010         0.001420        0.001223   \n",
       "5        0.000691      0.000006         0.000472        0.000008   \n",
       "6        0.000663      0.000035         0.000470        0.000033   \n",
       "7        0.000653      0.000051         0.000463        0.000051   \n",
       "8        0.000747      0.000017         0.000439        0.000008   \n",
       "9        0.000677      0.000027         0.000455        0.000007   \n",
       "10       0.000670      0.000019         0.000450        0.000016   \n",
       "11       0.000605      0.000030         0.000434        0.000026   \n",
       "\n",
       "   param_max_depth param_min_samples_leaf  \\\n",
       "0                6                      1   \n",
       "1                6                      2   \n",
       "2                6                      3   \n",
       "3                6                      4   \n",
       "4                8                      1   \n",
       "5                8                      2   \n",
       "6                8                      3   \n",
       "7                8                      4   \n",
       "8               12                      1   \n",
       "9               12                      2   \n",
       "10              12                      3   \n",
       "11              12                      4   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "0    {'max_depth': 6, 'min_samples_leaf': 1}           0.650560   \n",
       "1    {'max_depth': 6, 'min_samples_leaf': 2}           0.605647   \n",
       "2    {'max_depth': 6, 'min_samples_leaf': 3}           0.711139   \n",
       "3    {'max_depth': 6, 'min_samples_leaf': 4}           0.653774   \n",
       "4    {'max_depth': 8, 'min_samples_leaf': 1}           0.665404   \n",
       "5    {'max_depth': 8, 'min_samples_leaf': 2}           0.606669   \n",
       "6    {'max_depth': 8, 'min_samples_leaf': 3}           0.711139   \n",
       "7    {'max_depth': 8, 'min_samples_leaf': 4}           0.653774   \n",
       "8   {'max_depth': 12, 'min_samples_leaf': 1}           0.653402   \n",
       "9   {'max_depth': 12, 'min_samples_leaf': 2}           0.606521   \n",
       "10  {'max_depth': 12, 'min_samples_leaf': 3}           0.711139   \n",
       "11  {'max_depth': 12, 'min_samples_leaf': 4}           0.653774   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.454518           0.443423         0.516167        0.095138   \n",
       "1            0.601175           0.385572         0.530798        0.102707   \n",
       "2            0.554121           0.643152         0.636137        0.064294   \n",
       "3            0.554138           0.759628         0.655847        0.083904   \n",
       "4            0.483661           0.594600         0.581222        0.074797   \n",
       "5            0.536091           0.620258         0.587673        0.036893   \n",
       "6            0.556304           0.643152         0.636865        0.063367   \n",
       "7            0.554138           0.767558         0.658490        0.087192   \n",
       "8            0.461075           0.523088         0.545855        0.080151   \n",
       "9            0.464592           0.575129         0.548747        0.060871   \n",
       "10           0.566318           0.722725         0.666727        0.071158   \n",
       "11           0.554138           0.759628         0.655847        0.083904   \n",
       "\n",
       "    rank_test_score  \n",
       "0                12  \n",
       "1                11  \n",
       "2                 6  \n",
       "3                 3  \n",
       "4                 8  \n",
       "5                 7  \n",
       "6                 5  \n",
       "7                 2  \n",
       "8                10  \n",
       "9                 9  \n",
       "10                1  \n",
       "11                3  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe for results\n",
    "dt_df=pd.DataFrame(gs_dt.cv_results_)\n",
    "dt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40ce2bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5161666129081679 {'max_depth': 6, 'min_samples_leaf': 1}\n",
      "0.5307977285352904 {'max_depth': 6, 'min_samples_leaf': 2}\n",
      "0.6361373072429077 {'max_depth': 6, 'min_samples_leaf': 3}\n",
      "0.6558470491350702 {'max_depth': 6, 'min_samples_leaf': 4}\n",
      "0.581221803928772 {'max_depth': 8, 'min_samples_leaf': 1}\n",
      "0.5876725208463119 {'max_depth': 8, 'min_samples_leaf': 2}\n",
      "0.6368649761939776 {'max_depth': 8, 'min_samples_leaf': 3}\n",
      "0.6584903884368786 {'max_depth': 8, 'min_samples_leaf': 4}\n",
      "0.5458548662173023 {'max_depth': 12, 'min_samples_leaf': 1}\n",
      "0.5487471623990093 {'max_depth': 12, 'min_samples_leaf': 2}\n",
      "0.6667272732461086 {'max_depth': 12, 'min_samples_leaf': 3}\n",
      "0.6558470491350702 {'max_depth': 12, 'min_samples_leaf': 4}\n"
     ]
    }
   ],
   "source": [
    "#printing the evaluation scores\n",
    "cvres_dt=gs_dt.cv_results_\n",
    "for mean_score, params in zip(cvres_dt['mean_test_score'], cvres_dt['params']):\n",
    "    print((mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b172686",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f29af7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a Random forest instance\n",
    "rf=RandomForestRegressor()\n",
    "rf.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de1bad8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set 0.9770492890851423\n",
      "R2 Score of testing set 0.8756342808641262\n"
     ]
    }
   ],
   "source": [
    "#Printing the score of test and train set\n",
    "print(f'R2 Score of training set {rf.score(scaled_X_train, y_train)}')\n",
    "print(f'R2 Score of testing set {rf.score(scaled_X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd414923",
   "metadata": {},
   "source": [
    "#### Create a cross-valiation with five folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "31534556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.82831773, -12.2809754 ,  -9.87549159])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "cross_val_score(rf, scaled_X_train, y_train, scoring='neg_mean_absolute_error', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "556725c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 of Random Forest Regressor is 0.7641684423556724\n",
      "The mean squared error of Random Forest Regressor is 17.601576254338745\n",
      "The mean absolute error of Random Forest Regressor is 10.586950177372692\n"
     ]
    }
   ],
   "source": [
    "#score of training set using cross_val_score\n",
    "rf_r2=np.mean(cross_val_score(rf, scaled_X_train, y_train, cv=5))\n",
    "print(f'The R2 of Random Forest Regressor is {rf_r2}')\n",
    "\n",
    "#cross validation features gives greater is better, so score function is opposite of \n",
    "#MSE so we need to use -ve to get mse\n",
    "rf_mse=np.mean(cross_val_score(rf, scaled_X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\n",
    "rf_rmse=np.sqrt(-(lrl_mse))\n",
    "print(f'The mean squared error of Random Forest Regressor is {rf_rmse}')\n",
    "\n",
    "#mean absolute error\n",
    "rf_mae=np.mean(cross_val_score(rf, scaled_X_train, y_train, cv=5, scoring='neg_mean_absolute_error'))\n",
    "rf_mae=(-(rf_mae))\n",
    "print(f'The mean absolute error of Random Forest Regressor is {rf_mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266768d0",
   "metadata": {},
   "source": [
    "#### Tuning the hyperparameters using Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df27ebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [3, 6],\n",
       "                          'n_estimators': [30, 60, 100]}],\n",
       "             return_train_score=True, scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [{'n_estimators':[30,60,100],\n",
    "              'max_features':[3,6]}]\n",
    "              #,{'bootstrap':[False], 'n_estimators':[3,10,100],\n",
    "              #'max_features':[4,6,8,10]}]\n",
    "gs_rf=GridSearchCV(rf, parameters, scoring='neg_mean_absolute_error',\n",
    "                   cv=5, return_train_score=True)\n",
    "gs_rf.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de4ea0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 100}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4dc135e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=6)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best estimator\n",
    "rf_b=gs_rf.best_estimator_\n",
    "rf_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "625a7fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score of training set after hyperpar tuining 0.9619385519427943\n",
      "R2 Score of testing set after hyperpar tuining  0.8343700204582574\n"
     ]
    }
   ],
   "source": [
    "#Printing the score of test and train set\n",
    "rf_tr=rf_b.score(scaled_X_train, y_train)\n",
    "rf_te=rf_b.score(scaled_X_test, y_test)\n",
    "print(f'R2 Score of training set after hyperpar tuining {rf_tr}')\n",
    "print(f'R2 Score of testing set after hyperpar tuining  {rf_te}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34934d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023455</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 30}</td>\n",
       "      <td>-16.740499</td>\n",
       "      <td>-11.181536</td>\n",
       "      <td>-18.872831</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.691582</td>\n",
       "      <td>4.442282</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.857397</td>\n",
       "      <td>-5.783471</td>\n",
       "      <td>-4.962121</td>\n",
       "      <td>-5.578234</td>\n",
       "      <td>-5.618168</td>\n",
       "      <td>-5.359878</td>\n",
       "      <td>0.375372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042924</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 60}</td>\n",
       "      <td>-15.625204</td>\n",
       "      <td>-7.861880</td>\n",
       "      <td>-18.889295</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.753306</td>\n",
       "      <td>4.264868</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.936548</td>\n",
       "      <td>-4.840823</td>\n",
       "      <td>-5.559085</td>\n",
       "      <td>-5.125548</td>\n",
       "      <td>-6.025742</td>\n",
       "      <td>-5.297549</td>\n",
       "      <td>0.439812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.068176</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 3, 'n_estimators': 100}</td>\n",
       "      <td>-17.105603</td>\n",
       "      <td>-10.308832</td>\n",
       "      <td>-17.735118</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.613063</td>\n",
       "      <td>3.784373</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.087047</td>\n",
       "      <td>-6.245826</td>\n",
       "      <td>-4.900158</td>\n",
       "      <td>-5.413979</td>\n",
       "      <td>-5.685085</td>\n",
       "      <td>-5.666419</td>\n",
       "      <td>0.482467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021357</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 30}</td>\n",
       "      <td>-14.084976</td>\n",
       "      <td>-10.225766</td>\n",
       "      <td>-16.298083</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.248082</td>\n",
       "      <td>3.952485</td>\n",
       "      <td>3</td>\n",
       "      <td>-4.884345</td>\n",
       "      <td>-4.855745</td>\n",
       "      <td>-3.958600</td>\n",
       "      <td>-5.055853</td>\n",
       "      <td>-5.136767</td>\n",
       "      <td>-4.778262</td>\n",
       "      <td>0.423009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042118</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 60}</td>\n",
       "      <td>-13.018959</td>\n",
       "      <td>-8.877305</td>\n",
       "      <td>-16.841124</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.419222</td>\n",
       "      <td>3.753020</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.415935</td>\n",
       "      <td>-4.366880</td>\n",
       "      <td>-4.301275</td>\n",
       "      <td>-4.453005</td>\n",
       "      <td>-4.593902</td>\n",
       "      <td>-4.426199</td>\n",
       "      <td>0.098054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.071034</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 100}</td>\n",
       "      <td>-13.873342</td>\n",
       "      <td>-10.271755</td>\n",
       "      <td>-15.730342</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.243788</td>\n",
       "      <td>3.422687</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.369835</td>\n",
       "      <td>-4.618363</td>\n",
       "      <td>-4.510366</td>\n",
       "      <td>-3.920141</td>\n",
       "      <td>-5.131029</td>\n",
       "      <td>-4.509947</td>\n",
       "      <td>0.391152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.023455      0.003067         0.002023        0.000359   \n",
       "1       0.042924      0.003230         0.003260        0.000501   \n",
       "2       0.068176      0.001874         0.004991        0.000198   \n",
       "3       0.021357      0.000478         0.001727        0.000083   \n",
       "4       0.042118      0.000773         0.003098        0.000136   \n",
       "5       0.071034      0.003070         0.004837        0.000052   \n",
       "\n",
       "  param_max_features param_n_estimators  \\\n",
       "0                  3                 30   \n",
       "1                  3                 60   \n",
       "2                  3                100   \n",
       "3                  6                 30   \n",
       "4                  6                 60   \n",
       "5                  6                100   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0   {'max_features': 3, 'n_estimators': 30}         -16.740499   \n",
       "1   {'max_features': 3, 'n_estimators': 60}         -15.625204   \n",
       "2  {'max_features': 3, 'n_estimators': 100}         -17.105603   \n",
       "3   {'max_features': 6, 'n_estimators': 30}         -14.084976   \n",
       "4   {'max_features': 6, 'n_estimators': 60}         -13.018959   \n",
       "5  {'max_features': 6, 'n_estimators': 100}         -13.873342   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0         -11.181536         -18.872831  ...       -14.691582        4.442282   \n",
       "1          -7.861880         -18.889295  ...       -13.753306        4.264868   \n",
       "2         -10.308832         -17.735118  ...       -14.613063        3.784373   \n",
       "3         -10.225766         -16.298083  ...       -13.248082        3.952485   \n",
       "4          -8.877305         -16.841124  ...       -12.419222        3.753020   \n",
       "5         -10.271755         -15.730342  ...       -12.243788        3.422687   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                6           -4.857397           -5.783471   \n",
       "1                4           -4.936548           -4.840823   \n",
       "2                5           -6.087047           -6.245826   \n",
       "3                3           -4.884345           -4.855745   \n",
       "4                2           -4.415935           -4.366880   \n",
       "5                1           -4.369835           -4.618363   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0           -4.962121           -5.578234           -5.618168   \n",
       "1           -5.559085           -5.125548           -6.025742   \n",
       "2           -4.900158           -5.413979           -5.685085   \n",
       "3           -3.958600           -5.055853           -5.136767   \n",
       "4           -4.301275           -4.453005           -4.593902   \n",
       "5           -4.510366           -3.920141           -5.131029   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0         -5.359878         0.375372  \n",
       "1         -5.297549         0.439812  \n",
       "2         -5.666419         0.482467  \n",
       "3         -4.778262         0.423009  \n",
       "4         -4.426199         0.098054  \n",
       "5         -4.509947         0.391152  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe for results\n",
    "rf_df=pd.DataFrame(gs_rf.cv_results_)\n",
    "rf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "edee10d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.691581841140657 {'max_features': 3, 'n_estimators': 30}\n",
      "13.753305817647544 {'max_features': 3, 'n_estimators': 60}\n",
      "14.613063253702672 {'max_features': 3, 'n_estimators': 100}\n",
      "13.248082284240216 {'max_features': 6, 'n_estimators': 30}\n",
      "12.419222488482529 {'max_features': 6, 'n_estimators': 60}\n",
      "12.243788323956423 {'max_features': 6, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#printing the evaluation scores\n",
    "cvres=gs_rf.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print((-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6b0fea",
   "metadata": {},
   "source": [
    "### Important scores of each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a01b45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.33073214653520056, 'Age_Group'),\n",
       " (0.18537880070108823, 'Number_of_Asthma_ED_Visits'),\n",
       " (0.07998039026784715, 'CO AQI_mean'),\n",
       " (0.07071576925443791, 'SO2 AQI_mean'),\n",
       " (0.06653430995874669, 'CO AQI_max'),\n",
       " (0.04596810172414149, 'SO2 AQI_max'),\n",
       " (0.03777321318333694, 'O3 AQI_mean'),\n",
       " (0.036954036764261934, 'NO2 AQI_mean'),\n",
       " (0.03287830604496177, 'NO2 AQI_min'),\n",
       " (0.03006703754075322, 'O3 AQI_max'),\n",
       " (0.029881406732519097, 'O3 AQI_min'),\n",
       " (0.02862918022623617, 'NO2 AQI_max'),\n",
       " (0.015559449721367503, 'CO AQI_min'),\n",
       " (0.008376554932365634, 'Year'),\n",
       " (0.0005712964127356866, 'SO2 AQI_min')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances=rf_b.feature_importances_\n",
    "col=X.columns\n",
    "sorted(zip(feature_importances, col), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160c308",
   "metadata": {},
   "source": [
    "## Predicting on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af344ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model in test data\n",
    "y_pred_lr=lr.predict(scaled_X_test)     #linear \n",
    "y_pred_lrl=lrl.predict(scaled_X_test)   #lasso\n",
    "y_pred_lrr=lrr.predict(scaled_X_test)   #Ridge\n",
    "y_pred_svm=svm.predict(scaled_X_test)   #svm\n",
    "y_pred_dt=dt_b.predict(scaled_X_test)   #Dicision tree\n",
    "y_pred_rf=rf_b.predict(scaled_X_test)   #Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2209c159",
   "metadata": {},
   "source": [
    "### R2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "05de09b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2_score of linear regression is 0.8590207162163466\n",
      "The r2_score of lasso regression is 0.28237914152090693\n",
      "The r2_score of Ridge regression is -3041.1788073850216\n",
      "The r2_score of SVM regression is 0.4497650118953762\n",
      "The r2_score of decision tree regression is 0.7905140960979169\n",
      "The r2_score of random forest regression is 0.8343700204582574\n"
     ]
    }
   ],
   "source": [
    "#regression matrices-mean absolute error(give you the prediction error)\n",
    "lin_r2_lr=r2_score(y_test, y_pred_lr)\n",
    "print(f'The r2_score of linear regression is {lin_r2_lr}')\n",
    "\n",
    "lin_r2_lrl=r2_score(y_test, y_pred_lrl)\n",
    "print(f'The r2_score of lasso regression is {lin_r2_lrl}')\n",
    "\n",
    "lin_r2_lrr=r2_score(y_test, y_pred_lrr)\n",
    "print(f'The r2_score of Ridge regression is {lin_r2_lrr}')\n",
    "\n",
    "lin_r2_svm=r2_score(y_test, y_pred_svm)\n",
    "print(f'The r2_score of SVM regression is {lin_r2_svm}')\n",
    "\n",
    "lin_r2_dt=r2_score(y_test, y_pred_dt)\n",
    "print(f'The r2_score of decision tree regression is {lin_r2_dt}')\n",
    "\n",
    "lin_r2_rf=r2_score(y_test, y_pred_rf)\n",
    "print(f'The r2_score of random forest regression is {lin_r2_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a1c5b3",
   "metadata": {},
   "source": [
    "### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0f87316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absoulte error of linear regression is 11.53175879804626\n",
      "The mean absoulte error of lasso regression is 22.30432768732225\n",
      "The mean absoulte error of Ridge regression is 2001.6256317712132\n",
      "The mean absoulte error of SVM regression is 17.852929069793888\n",
      "The mean absoulte error of decision tree regression is 8.778868714866698\n",
      "The mean absoulte error of random forest regression is 10.867482024439479\n"
     ]
    }
   ],
   "source": [
    "#regression matrices-mean absolute error(give you the prediction error)\n",
    "lin_mae_lr=mean_absolute_error(y_test, y_pred_lr)\n",
    "print(f'The mean absoulte error of linear regression is {lin_mae_lr}')\n",
    "\n",
    "lin_mae_lrl=mean_absolute_error(y_test, y_pred_lrl)\n",
    "print(f'The mean absoulte error of lasso regression is {lin_mae_lrl}')\n",
    "\n",
    "lin_mae_lrr=mean_absolute_error(y_test, y_pred_lrr)\n",
    "print(f'The mean absoulte error of Ridge regression is {lin_mae_lrr}')\n",
    "\n",
    "lin_mae_svm=mean_absolute_error(y_test, y_pred_svm)\n",
    "print(f'The mean absoulte error of SVM regression is {lin_mae_svm}')\n",
    "\n",
    "lin_mae_dt=mean_absolute_error(y_test, y_pred_dt)\n",
    "print(f'The mean absoulte error of decision tree regression is {lin_mae_dt}')\n",
    "\n",
    "lin_mae_rf=mean_absolute_error(y_test, y_pred_rf)\n",
    "print(f'The mean absoulte error of random forest regression is {lin_mae_rf}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3c5b4",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64c2796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squared error of linear regression is 13.626880573788108\n",
      "The mean squared error of lasso regression is 30.74442156940809\n",
      "The mean squared error of ridge regression is 2001.7561346035948\n",
      "The mean squared error of SVM regression is 26.921106193008335\n",
      "The mean squared error of decision tree regression is 16.611016221632436\n",
      "The mean squared error of random forest regression is 14.770264546911061\n"
     ]
    }
   ],
   "source": [
    "#regression matrices-mean squared error(give you the prediction error)\n",
    "lin_mse_lr=mean_squared_error(y_test, y_pred_lr)\n",
    "lin_rmse_lr=np.sqrt(lin_mse_lr)\n",
    "print(f'The mean squared error of linear regression is {lin_rmse_lr}')\n",
    "\n",
    "lin_mse_lrl=mean_squared_error(y_test, y_pred_lrl)\n",
    "lin_rmse_lrl=np.sqrt(lin_mse_lrl)\n",
    "print(f'The mean squared error of lasso regression is {lin_rmse_lrl}')\n",
    "\n",
    "lin_mse_lrr=mean_squared_error(y_test, y_pred_lrr)\n",
    "lin_rmse_lrr=np.sqrt(lin_mse_lrr)\n",
    "print(f'The mean squared error of ridge regression is {lin_rmse_lrr}')\n",
    "\n",
    "lin_mse_svm=mean_squared_error(y_test, y_pred_svm)\n",
    "lin_rmse_svm=np.sqrt(lin_mse_svm)\n",
    "print(f'The mean squared error of SVM regression is {lin_rmse_svm}')\n",
    "\n",
    "lin_mse_dt=mean_squared_error(y_test, y_pred_dt)\n",
    "lin_rmse_dt=np.sqrt(lin_mse_dt)\n",
    "print(f'The mean squared error of decision tree regression is {lin_rmse_dt}')\n",
    "\n",
    "lin_mse_rf=mean_squared_error(y_test, y_pred_rf)\n",
    "lin_rmse_rf=np.sqrt(lin_mse_rf)\n",
    "print(f'The mean squared error of random forest regression is {lin_rmse_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3388cd03",
   "metadata": {},
   "source": [
    "### Actual and predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b1744326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value of Age_Adjusted_Rate</th>\n",
       "      <th>Random Forest Predicted Age_Adjusted_Ratee</th>\n",
       "      <th>Linear Reg Predicted Age_Adjusted_Rate</th>\n",
       "      <th>Lasso Reg Predicted Age_Adjusted_Rate</th>\n",
       "      <th>Ridge Reg Predicted Age_Adjusted_Rate</th>\n",
       "      <th>Decesion Tree Predicted Age_Adjusted_Rate</th>\n",
       "      <th>SVM Predicted Age_Adjusted_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.005882</td>\n",
       "      <td>54.922804</td>\n",
       "      <td>57.853872</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2036.609020</td>\n",
       "      <td>43.184271</td>\n",
       "      <td>45.816947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.950000</td>\n",
       "      <td>128.083935</td>\n",
       "      <td>130.065706</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2117.367526</td>\n",
       "      <td>116.248074</td>\n",
       "      <td>86.054744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.825000</td>\n",
       "      <td>54.664469</td>\n",
       "      <td>60.154127</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2049.654327</td>\n",
       "      <td>51.633790</td>\n",
       "      <td>47.236487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.671053</td>\n",
       "      <td>52.818674</td>\n",
       "      <td>62.899278</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2101.965301</td>\n",
       "      <td>40.088554</td>\n",
       "      <td>47.233532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.936111</td>\n",
       "      <td>84.116510</td>\n",
       "      <td>102.311064</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2103.547274</td>\n",
       "      <td>82.503334</td>\n",
       "      <td>67.591184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143.500000</td>\n",
       "      <td>104.271557</td>\n",
       "      <td>120.555908</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2119.500294</td>\n",
       "      <td>82.503334</td>\n",
       "      <td>83.338338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62.400000</td>\n",
       "      <td>64.318164</td>\n",
       "      <td>75.173226</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2094.735811</td>\n",
       "      <td>64.265000</td>\n",
       "      <td>51.911394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90.216279</td>\n",
       "      <td>98.637055</td>\n",
       "      <td>93.654035</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2103.623560</td>\n",
       "      <td>116.248074</td>\n",
       "      <td>67.558062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.738760</td>\n",
       "      <td>52.779125</td>\n",
       "      <td>45.536542</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2045.508951</td>\n",
       "      <td>43.184271</td>\n",
       "      <td>38.249753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.506522</td>\n",
       "      <td>62.057667</td>\n",
       "      <td>70.379924</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2048.792969</td>\n",
       "      <td>54.406266</td>\n",
       "      <td>48.641037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57.374545</td>\n",
       "      <td>52.735726</td>\n",
       "      <td>42.247016</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2036.011238</td>\n",
       "      <td>58.078686</td>\n",
       "      <td>43.260846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88.020690</td>\n",
       "      <td>81.179294</td>\n",
       "      <td>90.509049</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2103.645148</td>\n",
       "      <td>82.503334</td>\n",
       "      <td>64.551219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42.800000</td>\n",
       "      <td>67.573192</td>\n",
       "      <td>36.894615</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2042.725838</td>\n",
       "      <td>62.339959</td>\n",
       "      <td>24.175053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>82.608108</td>\n",
       "      <td>81.889921</td>\n",
       "      <td>83.866643</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2098.920638</td>\n",
       "      <td>80.664883</td>\n",
       "      <td>67.791131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>62.610145</td>\n",
       "      <td>62.437439</td>\n",
       "      <td>82.896120</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2099.072996</td>\n",
       "      <td>64.284214</td>\n",
       "      <td>51.852189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.602778</td>\n",
       "      <td>50.975513</td>\n",
       "      <td>45.518858</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2046.274406</td>\n",
       "      <td>51.633790</td>\n",
       "      <td>34.527713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30.440426</td>\n",
       "      <td>35.464940</td>\n",
       "      <td>8.181879</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2034.017788</td>\n",
       "      <td>26.554229</td>\n",
       "      <td>29.657505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>148.270588</td>\n",
       "      <td>116.364501</td>\n",
       "      <td>124.638865</td>\n",
       "      <td>75.909883</td>\n",
       "      <td>2110.379568</td>\n",
       "      <td>150.831343</td>\n",
       "      <td>77.916365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>24.567949</td>\n",
       "      <td>33.645768</td>\n",
       "      <td>21.182435</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2036.982106</td>\n",
       "      <td>24.362905</td>\n",
       "      <td>24.133790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>68.427273</td>\n",
       "      <td>63.948334</td>\n",
       "      <td>84.769791</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2039.991940</td>\n",
       "      <td>66.385205</td>\n",
       "      <td>65.589233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30.086667</td>\n",
       "      <td>48.296292</td>\n",
       "      <td>28.178587</td>\n",
       "      <td>56.997428</td>\n",
       "      <td>2026.370341</td>\n",
       "      <td>28.941474</td>\n",
       "      <td>31.487633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Value of Age_Adjusted_Rate  \\\n",
       "0                           46.005882   \n",
       "1                          142.950000   \n",
       "2                           52.825000   \n",
       "3                           42.671053   \n",
       "4                           95.936111   \n",
       "5                          143.500000   \n",
       "6                           62.400000   \n",
       "7                           90.216279   \n",
       "8                           38.738760   \n",
       "9                           55.506522   \n",
       "10                          57.374545   \n",
       "11                          88.020690   \n",
       "12                          42.800000   \n",
       "13                          82.608108   \n",
       "14                          62.610145   \n",
       "15                          55.602778   \n",
       "16                          30.440426   \n",
       "17                         148.270588   \n",
       "18                          24.567949   \n",
       "19                          68.427273   \n",
       "20                          30.086667   \n",
       "\n",
       "    Random Forest Predicted Age_Adjusted_Ratee  \\\n",
       "0                                    54.922804   \n",
       "1                                   128.083935   \n",
       "2                                    54.664469   \n",
       "3                                    52.818674   \n",
       "4                                    84.116510   \n",
       "5                                   104.271557   \n",
       "6                                    64.318164   \n",
       "7                                    98.637055   \n",
       "8                                    52.779125   \n",
       "9                                    62.057667   \n",
       "10                                   52.735726   \n",
       "11                                   81.179294   \n",
       "12                                   67.573192   \n",
       "13                                   81.889921   \n",
       "14                                   62.437439   \n",
       "15                                   50.975513   \n",
       "16                                   35.464940   \n",
       "17                                  116.364501   \n",
       "18                                   33.645768   \n",
       "19                                   63.948334   \n",
       "20                                   48.296292   \n",
       "\n",
       "    Linear Reg Predicted Age_Adjusted_Rate  \\\n",
       "0                                57.853872   \n",
       "1                               130.065706   \n",
       "2                                60.154127   \n",
       "3                                62.899278   \n",
       "4                               102.311064   \n",
       "5                               120.555908   \n",
       "6                                75.173226   \n",
       "7                                93.654035   \n",
       "8                                45.536542   \n",
       "9                                70.379924   \n",
       "10                               42.247016   \n",
       "11                               90.509049   \n",
       "12                               36.894615   \n",
       "13                               83.866643   \n",
       "14                               82.896120   \n",
       "15                               45.518858   \n",
       "16                                8.181879   \n",
       "17                              124.638865   \n",
       "18                               21.182435   \n",
       "19                               84.769791   \n",
       "20                               28.178587   \n",
       "\n",
       "    Lasso Reg Predicted Age_Adjusted_Rate  \\\n",
       "0                               56.997428   \n",
       "1                               75.909883   \n",
       "2                               56.997428   \n",
       "3                               75.909883   \n",
       "4                               75.909883   \n",
       "5                               75.909883   \n",
       "6                               75.909883   \n",
       "7                               75.909883   \n",
       "8                               56.997428   \n",
       "9                               56.997428   \n",
       "10                              56.997428   \n",
       "11                              75.909883   \n",
       "12                              56.997428   \n",
       "13                              75.909883   \n",
       "14                              75.909883   \n",
       "15                              56.997428   \n",
       "16                              56.997428   \n",
       "17                              75.909883   \n",
       "18                              56.997428   \n",
       "19                              56.997428   \n",
       "20                              56.997428   \n",
       "\n",
       "    Ridge Reg Predicted Age_Adjusted_Rate  \\\n",
       "0                             2036.609020   \n",
       "1                             2117.367526   \n",
       "2                             2049.654327   \n",
       "3                             2101.965301   \n",
       "4                             2103.547274   \n",
       "5                             2119.500294   \n",
       "6                             2094.735811   \n",
       "7                             2103.623560   \n",
       "8                             2045.508951   \n",
       "9                             2048.792969   \n",
       "10                            2036.011238   \n",
       "11                            2103.645148   \n",
       "12                            2042.725838   \n",
       "13                            2098.920638   \n",
       "14                            2099.072996   \n",
       "15                            2046.274406   \n",
       "16                            2034.017788   \n",
       "17                            2110.379568   \n",
       "18                            2036.982106   \n",
       "19                            2039.991940   \n",
       "20                            2026.370341   \n",
       "\n",
       "    Decesion Tree Predicted Age_Adjusted_Rate  SVM Predicted Age_Adjusted_Rate  \n",
       "0                                   43.184271                        45.816947  \n",
       "1                                  116.248074                        86.054744  \n",
       "2                                   51.633790                        47.236487  \n",
       "3                                   40.088554                        47.233532  \n",
       "4                                   82.503334                        67.591184  \n",
       "5                                   82.503334                        83.338338  \n",
       "6                                   64.265000                        51.911394  \n",
       "7                                  116.248074                        67.558062  \n",
       "8                                   43.184271                        38.249753  \n",
       "9                                   54.406266                        48.641037  \n",
       "10                                  58.078686                        43.260846  \n",
       "11                                  82.503334                        64.551219  \n",
       "12                                  62.339959                        24.175053  \n",
       "13                                  80.664883                        67.791131  \n",
       "14                                  64.284214                        51.852189  \n",
       "15                                  51.633790                        34.527713  \n",
       "16                                  26.554229                        29.657505  \n",
       "17                                 150.831343                        77.916365  \n",
       "18                                  24.362905                        24.133790  \n",
       "19                                  66.385205                        65.589233  \n",
       "20                                  28.941474                        31.487633  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual and predicated value of house using our best model\n",
    "house_value=pd.DataFrame({'Actual Value of Age_Adjusted_Rate':y_test, \n",
    "                'Random Forest Predicted Age_Adjusted_Ratee':y_pred_rf,\n",
    "                'Linear Reg Predicted Age_Adjusted_Rate':y_pred_lr,\n",
    "                'Lasso Reg Predicted Age_Adjusted_Rate':y_pred_lrl,\n",
    "                'Ridge Reg Predicted Age_Adjusted_Rate':y_pred_lrr,       \n",
    "                'Decesion Tree Predicted Age_Adjusted_Rate':y_pred_dt,\n",
    "                 'SVM Predicted Age_Adjusted_Rate':y_pred_svm})\n",
    "house_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9199c4",
   "metadata": {},
   "source": [
    "## Evaluation metrices of differnt models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0f013217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Reg</th>\n",
       "      <th>Lasso Reg</th>\n",
       "      <th>Ridge Reg</th>\n",
       "      <th>SVM Reg</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.859021</td>\n",
       "      <td>0.282379</td>\n",
       "      <td>-3041.178807</td>\n",
       "      <td>0.449765</td>\n",
       "      <td>0.790514</td>\n",
       "      <td>0.834370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>11.531759</td>\n",
       "      <td>22.304328</td>\n",
       "      <td>2001.625632</td>\n",
       "      <td>17.852929</td>\n",
       "      <td>8.778869</td>\n",
       "      <td>10.867482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <td>13.626881</td>\n",
       "      <td>30.744422</td>\n",
       "      <td>2001.756135</td>\n",
       "      <td>26.921106</td>\n",
       "      <td>16.611016</td>\n",
       "      <td>14.770265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Linear Reg  Lasso Reg    Ridge Reg    SVM Reg  \\\n",
       "R2                         0.859021   0.282379 -3041.178807   0.449765   \n",
       "Mean Absolute Error       11.531759  22.304328  2001.625632  17.852929   \n",
       "Root Mean Squared Error   13.626881  30.744422  2001.756135  26.921106   \n",
       "\n",
       "                         Decision Tree  Random Forest  \n",
       "R2                            0.790514       0.834370  \n",
       "Mean Absolute Error           8.778869      10.867482  \n",
       "Root Mean Squared Error      16.611016      14.770265  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making dataframe on evaluation metrices\n",
    "evaluation_df=pd.DataFrame({'Linear Reg':[lin_r2_lr,lin_mae_lr,lin_rmse_lr],\n",
    "                           'Lasso Reg':[lin_r2_lrl,lin_mae_lrl,lin_rmse_lrl],\n",
    "                            'Ridge Reg':[lin_r2_lrr,lin_mae_lrr,lin_rmse_lrr],\n",
    "                            'SVM Reg':[lin_r2_svm,lin_mae_svm,lin_rmse_svm],\n",
    "                           'Decision Tree':[lin_r2_dt,lin_mae_dt,lin_rmse_dt],\n",
    "                            'Random Forest':[lin_r2_rf,lin_mae_rf,lin_rmse_rf]}\n",
    "                           ,index=['R2','Mean Absolute Error',\n",
    "                                    'Root Mean Squared Error'])\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80931e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
